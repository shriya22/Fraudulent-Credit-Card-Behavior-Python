{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wNZNIBN0Lsvb",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Credit Card Default\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3KzMVGQlLsve",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Kaggle's Credit Card Fraud Dataset - RF\n",
    "\n",
    "\n",
    "\n",
    "The data is from: https://www.kaggle.com/mlg-ulb/creditcardfraud\n",
    "\n",
    "Note that there are 28 anonymized variables in the data set and the charge amount. The variable \"Class\" is 0 for no fraud and 1 if the charge was fraudulent. \n",
    "\n",
    "The data set is in your data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import os\n",
    "from ipypublish import nb_setup\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"DSTMAA_data/creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284807"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><i>There are 284807 observations in the data.</i></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1727485630620034"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((data.Class == 1).mean())*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The percentage of fradulent claims is 0.173%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependent categorical variable\n",
    "y = data.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop(columns = \"Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running a logistics regression for the training data\n",
    "model = LogisticRegression()\n",
    "model = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9989204485902945"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy on the training set\n",
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting y on training data set\n",
    "predicted_train = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[190408    124]\n",
      " [    82    206]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(predicted_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9989466628363497"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy on the test set\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[93792    66]\n",
      " [   33    96]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix \n",
    "print(confusion_matrix(predicted_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Since,our dataset is imbalanced the accuracy is only reflecting the underlying class distribution which in this case \n",
    "is majority non-fradulent cases. Therefore, we need to compute other metrices like precision, recall and F1 score\n",
    "using confusion matrix to detect overfitting.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    190532\n",
      "           1       0.62      0.72      0.67       288\n",
      "\n",
      "   micro avg       1.00      1.00      1.00    190820\n",
      "   macro avg       0.81      0.86      0.83    190820\n",
      "weighted avg       1.00      1.00      1.00    190820\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Computing precision, recall and F1 score for training data\n",
    "print(classification_report(predicted_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     93858\n",
      "           1       0.59      0.74      0.66       129\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     93987\n",
      "   macro avg       0.80      0.87      0.83     93987\n",
      "weighted avg       1.00      1.00      1.00     93987\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Computing precision, recall and F1 score for test data\n",
    "print(classification_report(predicted_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Recall is the important metric for our analysis, since bank would not like to incur losses due to fradulent charges.\n",
    "However, precision is also important since blocking genuine transactions can potentially lead to customer dissatisfaction. Therefore, we are looking at  F1 score to determine overfitting. Since F1 score has decreased only by 1%, there doesn't seem to be significant overfitting.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Apart from precision, recall and F1 score we have also computed AUC score and plotted the ROC curve </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.99994477e-01 5.52269625e-06]\n",
      " [9.99999742e-01 2.58332076e-07]\n",
      " [9.99999471e-01 5.28880637e-07]\n",
      " ...\n",
      " [9.98495813e-01 1.50418740e-03]\n",
      " [9.99997609e-01 2.39104045e-06]\n",
      " [9.99993325e-01 6.67509284e-06]]\n"
     ]
    }
   ],
   "source": [
    "# Generate class probabilities\n",
    "probs = model.predict_proba(X_test)\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9989466628363497\n",
      "AUC = 0.8985209527850971\n"
     ]
    }
   ],
   "source": [
    "# generate evaluation metrics\n",
    "print('Accuracy =', accuracy_score(y_test, predicted_test))\n",
    "print('AUC =', roc_auc_score(y_test, probs[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under curve (AUC):  0.8985209527850971\n"
     ]
    }
   ],
   "source": [
    "#ROC, AUC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "y_score = model.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "\n",
    "title('ROC curve')\n",
    "xlabel('FPR (1 - Specificity)')\n",
    "ylabel('TPR (Recall)')\n",
    "\n",
    "plot(fpr,tpr)\n",
    "plot((0,1), ls='dashed',color='black')\n",
    "plt.show()\n",
    "print('Area under curve (AUC): ', auc(fpr,tpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li><b>As explained earlier, since recall is the most important metric for fraud detection, a recall of 0.74 might be too low as it will ultimately result in business losses. </li>\n",
    "<li>Also, the AUC score of 89% is not satisfactory. This also reflected by the ROC curve which shows that for a TPR of greater than 0.8 increases the FPR at a higher rate which is not satisfactory for fraud detection. </li></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Cross Validation:</b> We are using CV for removing biasness by ensuring that the test-train split is random. This will also help us in identifying overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation on <b> Train Data : </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[190428,     62],\n",
       "       [   127,    203]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(model, X_train, y_train, cv=10)\n",
    "y_pred = cross_val_predict(model, X_train, y_train, cv=10)\n",
    "conf_mat = confusion_matrix(y_train, y_pred)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9990095377842995"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy :\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation model on <b> Test Data:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[93794,    31],\n",
       "       [   69,    93]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_test = cross_val_score(model, X_test, y_test, cv=10)\n",
    "y_pred_test = cross_val_predict(model, X_test, y_test, cv=10)\n",
    "conf_mat_test = confusion_matrix(y_test, y_pred_test)\n",
    "conf_mat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9989360253228998"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy on Test Data:\n",
    "scores_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    190555\n",
      "           1       0.62      0.77      0.68       265\n",
      "\n",
      "   micro avg       1.00      1.00      1.00    190820\n",
      "   macro avg       0.81      0.88      0.84    190820\n",
      "weighted avg       1.00      1.00      1.00    190820\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cross validation- classification report on train data:\n",
    "print(classification_report(y_pred, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     93863\n",
      "           1       0.57      0.75      0.65       124\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     93987\n",
      "   macro avg       0.79      0.87      0.82     93987\n",
      "weighted avg       1.00      1.00      1.00     93987\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cross validation- classification report on test data:\n",
    "print(classification_report(y_pred_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation improved the recall by 0.01. However, the F1 score decreased by 0.01. Also, CV did not indicate any significant overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation metrics results:\n",
    "1. Increased recall from 0.74 to 0.75 \n",
    "2. Decreased f1 score from 0.66 to 0.65\n",
    "3. Decreased precision from 0.59 to 0.57        \n",
    "\n",
    "Also, CV did not indicate any significant overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> SMOTE :</b> Since the data is imbalanced, we will use the oversampling method SMOTE to increase the number of records for minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total rows 380980\n",
      "non-fradulent 190490\n",
      "fradulent 190490\n"
     ]
    }
   ],
   "source": [
    "over = SMOTE(random_state=0)\n",
    "\n",
    "columns = X_train.columns\n",
    "\n",
    "over_X,over_Y = over.fit_sample(X_train, y_train)\n",
    "\n",
    "over_X = pd.DataFrame(data=over_X,columns=columns )\n",
    "\n",
    "over_Y= pd.DataFrame(data=over_Y,columns=['y'])\n",
    "\n",
    "print(\"total rows\",len(over_X))\n",
    "print(\"non-fradulent\",len(over_Y[over_Y['y']==0]))\n",
    "print(\"fradulent\",len(over_Y[over_Y['y']==1]))\n",
    "X_smote_train = over_X\n",
    "Y_smote_train = over_Y['y']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross validation over smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = LogisticRegression()\n",
    "model1 = model1.fit(X_smote_train, Y_smote_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[93794,    69],\n",
       "       [   31,    93]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_smote = cross_val_score(model1, X_smote_train, Y_smote_train, cv=10)\n",
    "y_pred_smote = cross_val_predict(model1, X_test, y_test, cv=10)\n",
    "conf_mat_smote = confusion_matrix(y_pred_smote,y_test)\n",
    "conf_mat_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9692949761142315"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_smote_test = cross_val_score(model1, X_test, y_test, cv=10)\n",
    "scores_smote.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     93863\n",
      "           1       0.57      0.75      0.65       124\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     93987\n",
      "   macro avg       0.79      0.87      0.82     93987\n",
      "weighted avg       1.00      1.00      1.00     93987\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cross validation- classification report on test data:\n",
    "print(classification_report(y_pred_smote, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Xgboost :</b> We are using Xgboost to improve the performance by penalizing the incorrect predicitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     93851\n",
      "           1       0.78      0.93      0.85       136\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     93987\n",
      "   macro avg       0.89      0.97      0.93     93987\n",
      "weighted avg       1.00      1.00      1.00     93987\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import *\n",
    "model2 = XGBClassifier(objective='reg:logistic')\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "y_pred1 = model2.predict(X_test)\n",
    "\n",
    "\n",
    "print(classification_report(y_pred1, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xgboost increased the performance of recall, precision and f1 score significantly.                                     \n",
    "1. Recall increased from 0.74 to 0.93                                          \n",
    "2. f1 score increased from 0.66 to 0.85                                        \n",
    "3. Precision increased from 0.59 to 0.78           \n",
    "   "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW1-CC_Fraud_Questions.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
